Setup Instructions
=====

1. Run `pod install`.
1. Download the `model_cpu.tflite` model from [the documentation](https://developers.google.com/mediapipe/solutions/genai/llm_inference#models) into this directory.
1. Open `InferenceExample.xcworkspace` and run the project.
